---
title: "Assignment 1"
output: 
  github_document:
    html_preview: false
  html_document:
    toc: yes
    toc_float: yes
    fig_height: 10
    fig_width: 10
    #code_folding: hide
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Part 1 
# Reading the Data
```{r}
if (!require(tidyverse)) {
  install.packages("tidyverse")}
if (!require(data.table)) {
  install.packages("data.table")}
air_2004 <- data.table::fread("2004_air.csv")
air_2019 <- data.table::fread("2019_air.csv")
```
# Check Dimensions
```{r}
dim(air_2004)
dim(air_2019)
```
# Check Headers and Footers
```{r}
head(air_2004)
head(air_2019)
tail(air_2004)
tail(air_2019)
```
# Check Variable Names and Variable Types
```{r}
str(air_2004)
str(air_2019)
```
# Key Variables
```{r}
#table(air_2004$Date)
#table(air_2019$Date)

```

# Continuous Variables
```{r}
summary(air_2004$`Daily Mean PM2.5 Concentration`)
summary(air_2019$`Daily Mean PM2.5 Concentration`)

##Checking to see if any NA's exist 
mean(is.na(air_2004$`Daily Mean PM2.5 Concentration`)) 
mean(is.na(air_2019$`Daily Mean PM2.5 Concentration`))
```

## Summary of Findings 

# Part 2

# Combining Data into One Data Frame, Creating Year Column, Changing names of key variables
```{r}
air_2004_2019 <- rbind(air_2004,air_2019)
#air_2004_2019$Year <- format(as.Date(air_2004_2019$Date, format="%m/%d/%Y"),"%Y")
air_2004_2019 <- mutate(air_2004_2019, year = factor(rep(c(2004, 2019), c(nrow(air_2004), nrow(air_2019)))))
colnames(air_2004_2019)[which(names(air_2004_2019) == "Daily Mean PM2.5 Concentration")] <- "PM2.5"
colnames(air_2004_2019)[which(names(air_2004_2019) == "SITE_LATITUDE")] <- "lat"
colnames(air_2004_2019)[which(names(air_2004_2019) == "SITE_LONGITUDE")] <- "lon"
air_2004_2019 <- air_2004_2019[PM2.5>=0][order(PM2.5)]
#summary(air_2004_2019$PM2.5)
#gplot(air_2004_2019) + 
  #geom_histogram(mapping = aes(x = PM2.5))
```

#Part 3

#Create Leaflet map showing the locations of the sites 
```{r}
library(leaflet)

temp.pal <- colorFactor(palette ='Accent', domain=air_2004_2019$year)

leaflet(air_2004_2019) %>%
  addProviderTiles('CartoDB.Positron') %>%
  addCircles(
    lat = ~lat, lng=~lon,
                                                  # HERE IS OUR PAL!
    label = air_2004_2019$`Site Name`, color = ~ temp.pal(air_2004_2019$year),
    opacity = 1, fillOpacity = 1, radius = 500
    ) %>%
  # And a pretty legend
  addLegend('bottomleft', pal=temp.pal, values=air_2004_2019$year,
          title='Year', opacity=1)
 # addMarkers(air_2004_2019$lon,air_2004_2019$lat, rank(-air_2004_2019$PM2.5) <= 10)
```
# Summarize the Spatial distribution of the monitoring sites

#Part 4

#Check for missing or implausible values of PM2.5 in the combined dataset 
```{r}
#table(air_2004_2019$PM2.5)
summary(air_2004_2019$PM2.5)
```

#Part 5

# Explore the main question of interest at three different spatial levels. Create exploratory plots (e.g. boxplots, histograms, line plots) and summary statistics that best suit each level of data. Be sure to write up explanations of what you observe in these data.
whether daily concentrations of PM (particulate matter air pollution with aerodynamic diameter less than 2.5 m) have decreased in California over the last 15 years (from 2004 to 2019)

##State

```{r}
library(ggplot2)
air_2004_2019[!is.na(PM2.5)] %>% 
  ggplot()+
  geom_boxplot(mapping=aes(x=year, y=log2(PM2.5), fill=year)) + labs(title = "PM2.5 Levels in California in 2004 and in 2019") +  labs(x = "Year", y = "log2([PM2.5])")
with(air_2004_2019, tapply(PM2.5, year, summary))
```
## County
```{r}
avg_pm_county <- group_by(air_2004_2019, year, COUNTY) %>% summarize(PM_AVG = mean(PM2.5, na.rm = TRUE))
tail(avg_pm_county)
temp.pal <- colorFactor(palette ='Accent', domain=avg_pm_county$COUNTY)
ggplot(data=avg_pm_county, aes(x=as.numeric(as.character(year)), y=PM_AVG, group=COUNTY)) +
  geom_line(color=temp.pal(avg_pm_county$COUNTY))+
  geom_point(color=temp.pal(avg_pm_county$COUNTY))+
  labs(title = "Average PM2.5 Levels Between 2004 to 2019 in All Counties") +  labs(x = "Year", y = "Average [PM2.5]") 



```

## Sites in Los Angeles 
```{r}
sites <- filter(air_2004_2019, COUNTY_CODE == 37) %>% select(COUNTY_CODE, `Site ID`, year) %>% unique
sites <- mutate(sites, site.code = paste(COUNTY_CODE, `Site ID`, sep = "."))
str(sites)
site.year <- with(sites, split(site.code, year))
both <- intersect(site.year[[1]], site.year[[2]])
print(both)
count <- mutate(air_2004_2019, site.code = paste(COUNTY_CODE, `Site ID`, sep = ".")) %>% filter(site.code %in% both)
group_by(count, site.code) %>% summarize(n = n())
#focus on Site ID 60371103
library(lubridate)
air_60371103 <- filter(air_2004_2019, COUNTY_CODE == "37" & `Site ID` == "60371103") %>% select(Date, year, PM2.5) %>%  mutate(Date = format(as.Date(Date,format="%Y/%m/%d")), yday = format(as.Date(Date,format="%Y/%d")))
qplot(Date, PM2.5, data = air_60371103, facets = . ~ year, xlab = "Day of the year")

```

