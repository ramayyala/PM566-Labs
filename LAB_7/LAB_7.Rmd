---
title: "Lab 7"
author: "Ram Ayyala"
date: "10/8/2021"
output: 
  html_document:
    toc: yes
    toc_float: yes
    html_preview: false
  github_document: 
  word_document: 
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Download the Data
```{r}
library(data.table)
library(stringr)
library(rvest)
library(xml2)
library(httr)
```

# Question 1: How many sars-cov-2 papers?
```{r}
# Downloading the website
website <- xml2::read_html("https://pubmed.ncbi.nlm.nih.gov/?term=sars-cov-2")

# Finding the counts
counts <- xml2::xml_find_first(website, "/html/body/main/div[9]/div[2]/div[2]/div[1]/span")

# Turning it into text
counts <- as.character(counts)

# Extracting the data using regex
stringr::str_extract(counts, "[0-9,]+")
stringr::str_replace(counts, "[^[:digit:]]+([[:digit:]]+),([[:digit:]]+)[^[:digit:]]+","\\1\\2")
```
# Question 2:Academic publications on COVID19 and Hawaii
```{r}
query_ids <- GET(
  url   = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi",
  query = list(db = "pubmed",term= "covid19 hawaii",retmax=1000)
)
ids <- httr::content(query_ids)
```

# Question 3: Get details about the articles
```{r}
# Turn the result into a character vector
ids <- as.character(ids)

# Find all the ids 
ids <- stringr::str_extract_all(ids, "<Id>[[:digit:]]+</Id>")[[1]]

# Remove all the leading and trailing <Id> </Id>. Make use of "|"
ids <- stringr::str_remove_all(ids, "<Id>|</Id>")
#Get the Publications
publications <- GET(
  url   = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi",
  query = list(
    db = "pubmed",id=I(paste(ids,collapse=",")),retmax=1000,rettype="abstract"
    )
)

# Turning the output into character vector
publications <- httr::content(publications)
publications_txt <- as.character(publications)
```

# Question 4: Distribution of universities, schools, and departments
```{r}
#University & Institute Case
institution <- str_extract_all(
  tolower(publications_txt),
  "university\\s+of\\s+(southern|new|northern|the)?\\s*[[:alpha:]-]+|[[:alpha:]-]+\\s+institute\\s+of\\s+[[:alpha:]-]+"
  ) 
institution <- unlist(institution)
table(institution)

schools_and_deps <- str_extract_all(
  tolower(publications_txt),
  "school\\s+of\\s+(medicine|population|social|biomedical|public|nursing|immunology|epidemiology)?\\s*[[:alpha:]-]+|[[:alpha:]-]+\\s+department\\s+of\\s+(health|internal|population|education|veterans)?\\s*[[:alpha:]-]+"
  )
table(schools_and_deps)

```

# Question 5: Form a database
```{r}
pub_char_list <- xml2::xml_children(publications)
pub_char_list <- sapply(pub_char_list, as.character)

abstracts <- str_extract(pub_char_list, "<Abstract>[[:print:][:space:]]+</Abstract>")
abstracts <- str_remove_all(abstracts, "</?[[:alnum:]- =\"]+>")
abstracts <- str_replace_all(abstracts, "[[:space:]]+", " ")

titles <- str_extract(pub_char_list, "<ArticleTitle>[[:print:][:space:]]+</ArticleTitle>")
titles <- str_remove_all(titles, "</?[[:alnum:]- =\"]+>")

database <- data.frame(
  PubMedId = ids,
  Title = titles,
  Abstract = abstracts
)
knitr::kable(database)
```

